{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nCc3XZEyG3XV"
   },
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 2, Sprint 3, Module 1*\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Define ML problems\n",
    "\n",
    "You will use your portfolio project dataset for all assignments this sprint.\n",
    "\n",
    "## Assignment\n",
    "\n",
    "Complete these tasks for your project, and document your decisions.\n",
    "\n",
    "- [ ] Choose your target. Which column in your tabular dataset will you predict?\n",
    "- [ ] Is your problem regression or classification?\n",
    "- [ ] How is your target distributed?\n",
    "    - Classification: How many classes? Are the classes imbalanced?\n",
    "    - Regression: Is the target right-skewed? If so, you may want to log transform the target.\n",
    "- [ ] Choose your evaluation metric(s).\n",
    "    - Classification: Is your majority class frequency >= 50% and < 70% ? If so, you can just use accuracy if you want. Outside that range, accuracy could be misleading. What evaluation metric will you choose, in addition to or instead of accuracy?\n",
    "    - Regression: Will you use mean absolute error, root mean squared error, R^2, or other regression metrics?\n",
    "- [ ] Choose which observations you will use to train, validate, and test your model.\n",
    "    - Are some observations outliers? Will you exclude them?\n",
    "    - Will you do a random split or a time-based split?\n",
    "- [ ] Begin to clean and explore your data.\n",
    "- [ ] Begin to choose which features, if any, to exclude. Would some features \"leak\" future information?\n",
    "\n",
    "If you haven't found a dataset yet, do that today. [Review requirements for your portfolio project](https://lambdaschool.github.io/ds/unit2) and choose your dataset.\n",
    "\n",
    "Some students worry, ***what if my model isn't “good”?*** Then, [produce a detailed tribute to your wrongness. That is science!](https://twitter.com/nathanwpyle/status/1176860147223867393)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle ML datasets (From 231 assignment)\n",
    "[ ] Continue to clean and explore your data.\n",
    "\n",
    "[ ] For the evaluation metric you chose, what score would you get just by guessing?\n",
    "\n",
    "[ ] Can you make a fast, first model that beats guessing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 2, Sprint 3, Module 3*\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Permutation & Boosting\n",
    "\n",
    "You will use your portfolio project dataset for all assignments this sprint.\n",
    "\n",
    "## Assignment\n",
    "\n",
    "Complete these tasks for your project, and document your work.\n",
    "\n",
    "- [ ] If you haven't completed assignment #1, please do so first.\n",
    "- [ ] Continue to clean and explore your data. Make exploratory visualizations.\n",
    "- [ ] Fit a model. Does it beat your baseline? \n",
    "- [ ] Try xgboost.\n",
    "- [ ] Get your model's permutation importances.\n",
    "\n",
    "You should try to complete an initial model today, because the rest of the week, we're making model interpretation visualizations.\n",
    "\n",
    "But, if you aren't ready to try xgboost and permutation importances with your dataset today, that's okay. You can practice with another dataset instead. You may choose any dataset you've worked with previously.\n",
    "\n",
    "The data subdirectory includes the Titanic dataset for classification and the NYC apartments dataset for regression. You may want to choose one of these datasets, because example solutions will be available for each.\n",
    "\n",
    "\n",
    "## Reading\n",
    "\n",
    "Top recommendations in _**bold italic:**_\n",
    "\n",
    "#### Permutation Importances\n",
    "- _**[Kaggle / Dan Becker: Machine Learning Explainability](https://www.kaggle.com/dansbecker/permutation-importance)**_\n",
    "- [Christoph Molnar: Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/feature-importance.html)\n",
    "\n",
    "#### (Default) Feature Importances\n",
    "  - [Ando Saabas: Selecting good features, Part 3, Random Forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
    "  - [Terence Parr, et al: Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
    "\n",
    "#### Gradient Boosting\n",
    "  - [A Gentle Introduction to the Gradient Boosting Algorithm for Machine Learning](https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/)\n",
    "  - [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf), Chapter 8\n",
    "  - _**[Gradient Boosting Explained](https://www.gormanalysis.com/blog/gradient-boosting-explained/)**_ — Ben Gorman\n",
    "  - [Gradient Boosting Explained](http://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html) — Alex Rogozhnikov\n",
    "  - [How to explain gradient boosting](https://explained.ai/gradient-boosting/) — Terence Parr & Jeremy Howard\n",
    "  \n",
    "# Model Interpretation\n",
    "\n",
    "You will use your portfolio project dataset for all assignments this sprint.\n",
    "\n",
    "## Assignment\n",
    "\n",
    "Complete these tasks for your project, and document your work.\n",
    "\n",
    "- [ ] Continue to iterate on your project: data cleaning, exploratory visualization, feature engineering, modeling.\n",
    "- [ ] Make at least 1 partial dependence plot to explain your model.\n",
    "- [ ] Make at least 1 Shapley force plot to explain an individual prediction.\n",
    "- [ ] **Share at least 1 visualization (of any type) on Slack!**\n",
    "\n",
    "If you aren't ready to make these plots with your own dataset, you can practice these objectives with any dataset you've worked with previously. Example solutions are available for Partial Dependence Plots with the Tanzania Waterpumps dataset, and Shapley force plots with the Titanic dataset. (These datasets are available in the data directory of this repository.)\n",
    "\n",
    "Please be aware that **multi-class classification** will result in multiple Partial Dependence Plots (one for each class), and multiple sets of Shapley Values (one for each class).\n",
    "\n",
    "## Stretch Goals\n",
    "\n",
    "#### Partial Dependence Plots\n",
    "- [ ] Make multiple PDPs with 1 feature in isolation.\n",
    "- [ ] Make multiple PDPs with 2 features in interaction. \n",
    "- [ ] Use Plotly to make a 3D PDP.\n",
    "- [ ] Make PDPs with categorical feature(s). Use Ordinal Encoder, outside of a pipeline, to encode your data first. If there is a natural ordering, then take the time to encode it that way, instead of random integers. Then use the encoded data with pdpbox. Get readable category names on your plot, instead of integer category codes.\n",
    "\n",
    "#### Shap Values\n",
    "- [ ] Make Shapley force plots to explain at least 4 individual predictions.\n",
    "    - If your project is Binary Classification, you can do a True Positive, True Negative, False Positive, False Negative.\n",
    "    - If your project is Regression, you can do a high prediction with low error, a low prediction with low error, a high prediction with high error, and a low prediction with high error.\n",
    "- [ ] Use Shapley values to display verbal explanations of individual predictions.\n",
    "- [ ] Use the SHAP library for other visualization types.\n",
    "\n",
    "The [SHAP repo](https://github.com/slundberg/shap) has examples for many visualization types, including:\n",
    "\n",
    "- Force Plot, individual predictions\n",
    "- Force Plot, multiple predictions\n",
    "- Dependence Plot\n",
    "- Summary Plot\n",
    "- Summary Plot, Bar\n",
    "- Interaction Values\n",
    "- Decision Plots\n",
    "\n",
    "We just did the first type during the lesson. The [Kaggle microcourse](https://www.kaggle.com/dansbecker/advanced-uses-of-shap-values) shows two more. Experiment and see what you can learn!\n",
    "\n",
    "### Links\n",
    "\n",
    "#### Partial Dependence Plots\n",
    "- [Kaggle / Dan Becker: Machine Learning Explainability — Partial Dependence Plots](https://www.kaggle.com/dansbecker/partial-plots)\n",
    "- [Christoph Molnar: Interpretable Machine Learning — Partial Dependence Plots](https://christophm.github.io/interpretable-ml-book/pdp.html) + [animated explanation](https://twitter.com/ChristophMolnar/status/1066398522608635904)\n",
    "- [pdpbox repo](https://github.com/SauceCat/PDPbox) & [docs](https://pdpbox.readthedocs.io/en/latest/)\n",
    "- [Plotly: 3D PDP example](https://plot.ly/scikit-learn/plot-partial-dependence/#partial-dependence-of-house-value-on-median-age-and-average-occupancy)\n",
    "\n",
    "#### Shapley Values\n",
    "- [Kaggle / Dan Becker: Machine Learning Explainability — SHAP Values](https://www.kaggle.com/learn/machine-learning-explainability)\n",
    "- [Christoph Molnar: Interpretable Machine Learning — Shapley Values](https://christophm.github.io/interpretable-ml-book/shapley.html)\n",
    "- [SHAP repo](https://github.com/slundberg/shap) & [docs](https://shap.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# If you're on Colab:\n",
    "if 'google.colab' in sys.modules:\n",
    "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n",
    "\n",
    "# If you're working locally:\n",
    "else:\n",
    "    DATA_PATH = '../data/'\n",
    "    \n",
    "# Ignore this Numpy warning when using Plotly Express:\n",
    "# FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning, module='numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('/Users/bradbrauser/Desktop/Data Science/MoviesOnStreamingPlatforms_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16744, 17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which column in your tabular dataset will you predict, and how is your target distributed?\n",
    "\n",
    "The dataset has two rating features - IMDb and Rotten Tomatoes.\n",
    "\n",
    "IMDb is great for seeing what general audiences think of a movie. If you don’t care what the critics say and want to see what people like yourself think of a movie, then you should use IMDb. Just be aware that fans often skew the vote with 10-star ratings, which may inflate scores somewhat.\n",
    "\n",
    "Rotten Tomatoes offers the best overall picture of whether a movie is worth seeing at a glance. If you only trust the opinions of top critics and just want to know if a movie is at least decent, you should use Rotten Tomatoes. While the Fresh/Rotten binary can oversimplify the often complex opinions of critics, it should still help you weed out lousy films.\n",
    "\n",
    "My goal with this project is more in line with IMDb, as even though scores may be skewed a bit by fans of the movies, I still want to know what the public thinks, because it seems that more often than not critics do not always line up with the public opinion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571\n",
      "11586\n"
     ]
    }
   ],
   "source": [
    "print(df['IMDb'].isnull().sum())\n",
    "print(df['Rotten Tomatoes'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['13+', '18+', '7+', nan, 'all', '16+'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the Rotten Tomatoes features has over 11,000 missing ratings, \n",
    "# I'm going to just drop the Rotten Tomatoes column\n",
    "\n",
    "df = df.drop(['Rotten Tomatoes'], axis = 1)\n",
    "df['Age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Age</th>\n",
       "      <th>IMDb</th>\n",
       "      <th>Netflix</th>\n",
       "      <th>Hulu</th>\n",
       "      <th>Prime Video</th>\n",
       "      <th>Disney+</th>\n",
       "      <th>Type</th>\n",
       "      <th>Directors</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Country</th>\n",
       "      <th>Language</th>\n",
       "      <th>Runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Inception</td>\n",
       "      <td>2010</td>\n",
       "      <td>13+</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>Action,Adventure,Sci-Fi,Thriller</td>\n",
       "      <td>United States,United Kingdom</td>\n",
       "      <td>English,Japanese,French</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>The Matrix</td>\n",
       "      <td>1999</td>\n",
       "      <td>18+</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lana Wachowski,Lilly Wachowski</td>\n",
       "      <td>Action,Sci-Fi</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Avengers: Infinity War</td>\n",
       "      <td>2018</td>\n",
       "      <td>13+</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Anthony Russo,Joe Russo</td>\n",
       "      <td>Action,Adventure,Sci-Fi</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Back to the Future</td>\n",
       "      <td>1985</td>\n",
       "      <td>7+</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Robert Zemeckis</td>\n",
       "      <td>Adventure,Comedy,Sci-Fi</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>The Good, the Bad and the Ugly</td>\n",
       "      <td>1966</td>\n",
       "      <td>18+</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sergio Leone</td>\n",
       "      <td>Western</td>\n",
       "      <td>Italy,Spain,West Germany</td>\n",
       "      <td>Italian</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ID                           Title  Year  Age  IMDb  Netflix  \\\n",
       "0           0   1                       Inception  2010  13+   8.8        1   \n",
       "1           1   2                      The Matrix  1999  18+   8.7        1   \n",
       "2           2   3          Avengers: Infinity War  2018  13+   8.5        1   \n",
       "3           3   4              Back to the Future  1985   7+   8.5        1   \n",
       "4           4   5  The Good, the Bad and the Ugly  1966  18+   8.8        1   \n",
       "\n",
       "   Hulu  Prime Video  Disney+  Type                       Directors  \\\n",
       "0     0            0        0     0               Christopher Nolan   \n",
       "1     0            0        0     0  Lana Wachowski,Lilly Wachowski   \n",
       "2     0            0        0     0         Anthony Russo,Joe Russo   \n",
       "3     0            0        0     0                 Robert Zemeckis   \n",
       "4     0            1        0     0                    Sergio Leone   \n",
       "\n",
       "                             Genres                       Country  \\\n",
       "0  Action,Adventure,Sci-Fi,Thriller  United States,United Kingdom   \n",
       "1                     Action,Sci-Fi                 United States   \n",
       "2           Action,Adventure,Sci-Fi                 United States   \n",
       "3           Adventure,Comedy,Sci-Fi                 United States   \n",
       "4                           Western      Italy,Spain,West Germany   \n",
       "\n",
       "                  Language  Runtime  \n",
       "0  English,Japanese,French    148.0  \n",
       "1                  English    136.0  \n",
       "2                  English    149.0  \n",
       "3                  English    116.0  \n",
       "4                  Italian    161.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=['IMDb'], how='all')\n",
    "df['IMDb'].isnull().sum()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(df, thresh=500):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Setting Title as index\n",
    "    df.set_index(df['Title'], inplace = True)    \n",
    "    \n",
    "    # Dropping rows if nulls exist\n",
    "    df.dropna(subset=['IMDb'], how='all')\n",
    "    \n",
    "#     # Creating new Rating colums\n",
    "#     df['Worth Watching?'] = df['IMDb'] >= 6.6\n",
    "    \n",
    "    # Creating rating column based on letter grades\n",
    "    names = {'First_name': ['Jon','Bill','Maria','Emma']}\n",
    "    \n",
    "#     # Replacing values in Age column\n",
    "#     df['Age'] = df['Age'].replace(to_replace =\"13+\", value = 'PG')\n",
    "#     df['Age'] = df['Age'].replace(to_replace =\"18+\", value = 'R')\n",
    "#     df['Age'] = df['Age'].replace(to_replace =\"7+\", value = 'G')\n",
    "#     df['Age'] = df['Age'].replace(to_replace =\"all\", value = 'G')\n",
    "#     df['Age'] = df['Age'].replace(to_replace =\"16+\", value = 'PG-13')\n",
    "    \n",
    "    # Rename Age to MPAA Rating\n",
    "    df = df.rename(columns = {'Age': 'MPAA Rating'})\n",
    "    \n",
    "    # Creating individual genre columns\n",
    "    df['Action'] = df['Genres'].str.contains('Action')\n",
    "    df['Adventure'] = df['Genres'].str.contains('Adventure')\n",
    "    df['Animation'] = df['Genres'].str.contains('Animation')\n",
    "    df['Biography'] = df['Genres'].str.contains('Biography')\n",
    "    df['Comedy'] = df['Genres'].str.contains('Comedy')\n",
    "    df['Crime'] = df['Genres'].str.contains('Crime')\n",
    "    df['Documentary'] = df['Genres'].str.contains('Documentary')\n",
    "    df['Drama'] = df['Genres'].str.contains('Drama')\n",
    "    df['Family'] = df['Genres'].str.contains('Family')\n",
    "    df['Fantasy'] = df['Genres'].str.contains('Fantasy')\n",
    "    df['Film Noir'] = df['Genres'].str.contains('Film Noir')\n",
    "    df['History'] = df['Genres'].str.contains('History')\n",
    "    df['Horror'] = df['Genres'].str.contains('Horror')\n",
    "    df['Music'] = df['Genres'].str.contains('Music')\n",
    "    df['Musical'] = df['Genres'].str.contains('Musical')\n",
    "    df['Mystery'] = df['Genres'].str.contains('Mystery')\n",
    "    df['Romance'] = df['Genres'].str.contains('Romance')\n",
    "    df['Sci-Fi'] = df['Genres'].str.contains('Sci-Fi')\n",
    "    df['Short Film'] = df['Genres'].str.contains('Short Film')\n",
    "    df['Sport'] = df['Genres'].str.contains('Sport')\n",
    "    df['Superhero'] = df['Genres'].str.contains('Superhero')\n",
    "    df['Thriller'] = df['Genres'].str.contains('Thriller')\n",
    "    df['War'] = df['Genres'].str.contains('War')\n",
    "    df['Western'] = df['Genres'].str.contains('Western')\n",
    "\n",
    "    # Dropping unnecessary values\n",
    "    df.drop(['Genres', 'Unnamed: 0', 'ID', 'Type', 'Title', 'IMDb'], axis=1, inplace=True)\n",
    "    \n",
    "    # Dropping other nulls\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Split label and feature matrix\n",
    "    y = df['Worth Watching?']\n",
    "    df.drop(['Worth Watching?'], axis=1, inplace=True)\n",
    "    \n",
    "    return df, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Wrong number of items passed 17, placement implies 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Rating'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Rating'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-209e3704630e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Wrangling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-05d82ad7d8b6>\u001b[0m in \u001b[0;36mwrangle\u001b[0;34m(df, thresh)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Worth Watching?'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IMDb'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m6.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Rating'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#     # Replacing values in Age column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2937\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2938\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3000\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3001\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m         \u001b[0;31m# check if we are modifying a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3623\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3624\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3625\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value)\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;31m# This item wasn't present, just insert at end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblkno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_fast_count_smallints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   3051\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatetimeArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3053\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m   2599\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2601\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2603\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_ndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             raise ValueError(\n\u001b[0;32m--> 125\u001b[0;31m                 \u001b[0;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m                 \u001b[0;34mf\"placement implies {len(self.mgr_locs)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 17, placement implies 1"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Wrangling\n",
    "X, y = wrangle(df)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.67585\n",
       "True     0.32415\n",
       "Name: Worth Watching?, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train test split on years movies were released\n",
    "cutoff = 2010\n",
    "X_train = X[X['Year'] < cutoff]\n",
    "y_train = y.loc[X_train.index]\n",
    "X_val = X[X['Year'] > cutoff]\n",
    "y_val = y.loc[X_val.index]\n",
    "\n",
    "# # Baseline\n",
    "y_train.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import category_encoders as ce\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.5847851335656213\n"
     ]
    }
   ],
   "source": [
    "# Building model 1\n",
    "model1 = Pipeline([\n",
    "    ('oe', OrdinalEncoder()),\n",
    "    ('impute', SimpleImputer()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(criterion='entropy', \n",
    "                                          max_depth=50, n_estimators=200, \n",
    "                                          min_samples_leaf=1, \n",
    "                                          random_state=42))\n",
    "])\n",
    "\n",
    "# Fitting the model\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "print('Training Accuracy:', model1.score(X_train, y_train))\n",
    "print('Validation Accuracy:', model1.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9991207502930832\n",
      "Validation Accuracy: 0.7322880371660859\n"
     ]
    }
   ],
   "source": [
    "# Building model 2\n",
    "model2 = Pipeline([\n",
    "                  ('ohe', OneHotEncoder()),\n",
    "                  ('impute', SimpleImputer()),\n",
    "                  ('scaler', StandardScaler()),\n",
    "                  ('classifier', RandomForestClassifier(criterion='entropy', \n",
    "                                                        max_depth=74, \n",
    "                                                        n_estimators=149, \n",
    "                                                        min_samples_leaf=1, \n",
    "                                                        random_state=42))\n",
    "])\n",
    "\n",
    "# Fitting the model\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "print('Training Accuracy:', model2.score(X_train, y_train))\n",
    "print('Validation Accuracy:', model2.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8599062133645955\n",
      "Validation Accuracy: 0.7479674796747967\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "tree_model = make_pipeline(\n",
    "    ce.OneHotEncoder(), \n",
    "    SimpleImputer(), \n",
    "    StandardScaler(), \n",
    "    RandomForestClassifier(criterion='entropy', \n",
    "                           max_depth=74, \n",
    "                           n_estimators=149, \n",
    "                           min_samples_leaf=1, \n",
    "                           random_state=42, \n",
    "                           min_samples_split = 40))\n",
    "\n",
    "# Fitting the model\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "print('Training Accuracy:', tree_model.score(X_train, y_train))\n",
    "print('Validation Accuracy:', tree_model.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Model\n",
    "lin_model = make_pipeline(\n",
    "    ce.OneHotEncoder(), \n",
    "    SimpleImputer(), \n",
    "    StandardScaler(), \n",
    "    LogisticRegression(max_iter = 3))\n",
    "\n",
    "lin_model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 5 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradbrauser/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 5 is smaller than n_iter=40. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  35 | elapsed:    8.3s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  35 | elapsed:    8.4s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    9.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Best Score: 0.616731145617435\n",
      "Best Estimator: {'randomforestclassifier__max_depth': 11}\n",
      "Best Model: Pipeline(steps=[('ordinalencoder',\n",
      "                 OrdinalEncoder(cols=['MPAA Rating', 'Directors', 'Country',\n",
      "                                      'Action', 'Adventure', 'Animation',\n",
      "                                      'Biography', 'Comedy', 'Crime',\n",
      "                                      'Documentary', 'Drama', 'Family',\n",
      "                                      'Fantasy', 'Film Noir', 'History',\n",
      "                                      'Horror', 'Music', 'Musical', 'Mystery',\n",
      "                                      'Romance', 'Sci-Fi', 'Short Film',\n",
      "                                      'Sport', 'Superhero', 'Thriller', 'War',\n",
      "                                      'Western'],\n",
      "                                mapping=[{'col': 'MPA...\n",
      "dtype: int64},\n",
      "                                         {'col': 'War', 'data_type': dtype('O'),\n",
      "                                          'mapping': False    1\n",
      "True     2\n",
      "NaN     -2\n",
      "dtype: int64},\n",
      "                                         {'col': 'Western',\n",
      "                                          'data_type': dtype('O'),\n",
      "                                          'mapping': False    1\n",
      "True     2\n",
      "NaN     -2\n",
      "dtype: int64}])),\n",
      "                ('simpleimputer', SimpleImputer()),\n",
      "                ('standardscaler', StandardScaler()),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=11, min_samples_split=3,\n",
      "                                        n_estimators=200, n_jobs=1))])\n"
     ]
    }
   ],
   "source": [
    "# Model 4\n",
    "model4 = make_pipeline(\n",
    "  OrdinalEncoder(),\n",
    "  SimpleImputer(),\n",
    "  StandardScaler(),\n",
    "  RandomForestClassifier(\n",
    "      min_samples_split=3,\n",
    "      max_depth=15,\n",
    "      n_estimators= 200,\n",
    "      n_jobs=1)\n",
    ")\n",
    "\n",
    "param_distributions = {\n",
    "    'randomforestclassifier__max_depth' : (11, 12, 13, 14, 15),\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    model4,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=40,\n",
    "    cv=7,\n",
    "    scoring='accuracy',\n",
    "    verbose = 30,\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print('Cross-validation Best Score:', search.best_score_)\n",
    "print('Best Estimator:', search.best_params_)\n",
    "print('Best Model:', search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9897420867526378\n",
      "Validation Accuracy: 0.5691056910569106\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model5 = make_pipeline(ce.OrdinalEncoder(),\n",
    "                       SimpleImputer(), \n",
    "                       StandardScaler(),\n",
    "                       XGBClassifier()\n",
    ")\n",
    "\n",
    "model5.fit(X_train, y_train)\n",
    "\n",
    "print('Training Accuracy:', model5.score(X_train, y_train))\n",
    "print('Validation Accuracy:', model5.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fb63b9dad50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plot_confusion_matrix(model5, X_val, y_val, values_format='.0f', xticks_rotation='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.44      0.58      2317\n",
      "        True       0.42      0.83      0.56      1127\n",
      "\n",
      "    accuracy                           0.57      3444\n",
      "   macro avg       0.63      0.64      0.57      3444\n",
      "weighted avg       0.70      0.57      0.57      3444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model5.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "Avengers: Infinity War               1\n",
      "Spider-Man: Into the Spider-Verse    1\n",
      "Django Unchained                     1\n",
      "Room                                 1\n",
      "Her                                  1\n",
      "Name: Netflix, dtype: int64\n",
      "\n",
      "0    2265\n",
      "1    1179\n",
      "Name: Netflix, dtype: int64\n",
      "Validation accuracy with Netflix: 0.5691056910569106\n",
      "Validation accuracy with Netflix permuted: 0.5455865272938444\n",
      "Permutation importance: 0.023519163763066175\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "feature = 'Netflix'\n",
    "print(X_val[feature].head())\n",
    "print()\n",
    "print(X_val[feature].value_counts())\n",
    "\n",
    "X_val_permuted = X_val.copy()\n",
    "X_val_permuted[feature] = np.random.permutation(X_val_permuted[feature])\n",
    "\n",
    "acc = model5.score(X_val, y_val)\n",
    "acc_permuted = model5.score(X_val_permuted, y_val)\n",
    "\n",
    "print(f'Validation accuracy with {feature}:', acc)\n",
    "print(f'Validation accuracy with {feature} permuted:', acc_permuted)\n",
    "print(f'Permutation importance:', acc - acc_permuted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradbrauser/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/bradbrauser/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=20, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "# Ignore warnings\n",
    "\n",
    "model8 = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='median')\n",
    ")\n",
    "\n",
    "X_train_transformed = model8.fit_transform(X_train)\n",
    "X_val_transformed = model8.transform(X_val)\n",
    "\n",
    "model8 = RandomForestClassifier(n_estimators=20, random_state=42, n_jobs=-1)\n",
    "model8.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradbrauser/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 25 is smaller than n_iter=40. Running 25 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 25 candidates, totalling 175 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=4)]: Done  11 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=4)]: Done  13 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=4)]: Done  15 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=4)]: Done  16 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=4)]: Done  18 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=4)]: Done  19 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=4)]: Done  20 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=4)]: Done  21 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=4)]: Done  22 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=4)]: Done  23 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=4)]: Done  25 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=4)]: Done  26 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=4)]: Done  27 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=4)]: Done  28 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=4)]: Done  29 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=4)]: Done  30 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=4)]: Done  31 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=4)]: Done  32 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=4)]: Done  34 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=4)]: Done  35 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=4)]: Done  36 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=4)]: Done  37 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=4)]: Done  38 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=4)]: Done  39 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=4)]: Done  40 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=4)]: Done  41 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=4)]: Done  43 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=4)]: Done  44 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=4)]: Done  45 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=4)]: Done  46 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=4)]: Done  47 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=4)]: Done  48 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=4)]: Done  49 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=4)]: Done  50 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=4)]: Done  51 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=4)]: Done  52 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=4)]: Done  54 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=4)]: Done  55 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=4)]: Done  56 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=4)]: Done  57 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=4)]: Done  59 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=4)]: Done  60 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=4)]: Done  61 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=4)]: Done  62 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=4)]: Done  63 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=4)]: Done  65 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=4)]: Done  66 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=4)]: Done  67 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=4)]: Done  68 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=4)]: Done  69 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=4)]: Done  70 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=4)]: Done  71 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=4)]: Done  72 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=4)]: Done  73 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=4)]: Done  74 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=4)]: Done  75 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=4)]: Done  78 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=4)]: Done  79 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=4)]: Done  80 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=4)]: Done  81 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=4)]: Done  82 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=4)]: Done  83 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=4)]: Done  84 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=4)]: Done  85 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=4)]: Done  86 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=4)]: Done  87 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=4)]: Done  88 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=4)]: Done  89 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=4)]: Done  91 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=4)]: Done  92 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=4)]: Done  93 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=4)]: Done  94 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=4)]: Done  95 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=4)]: Done  96 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=4)]: Done  97 tasks      | elapsed:   22.4s\n",
      "[Parallel(n_jobs=4)]: Done  98 tasks      | elapsed:   22.4s\n",
      "[Parallel(n_jobs=4)]: Done  99 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=4)]: Done 100 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=4)]: Done 101 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=4)]: Done 102 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=4)]: Done 103 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=4)]: Done 104 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=4)]: Done 106 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=4)]: Done 107 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=4)]: Done 108 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=4)]: Done 109 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=4)]: Done 110 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=4)]: Done 111 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=4)]: Done 112 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=4)]: Done 113 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=4)]: Done 114 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=4)]: Done 115 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=4)]: Done 116 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=4)]: Done 117 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=4)]: Done 118 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=4)]: Done 119 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=4)]: Done 121 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=4)]: Done 122 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=4)]: Done 123 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=4)]: Done 124 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=4)]: Done 125 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=4)]: Done 126 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=4)]: Done 127 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=4)]: Done 128 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=4)]: Done 129 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=4)]: Done 130 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=4)]: Done 131 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=4)]: Done 132 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=4)]: Done 133 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=4)]: Done 134 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=4)]: Done 135 tasks      | elapsed:   30.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 136 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=4)]: Done 138 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=4)]: Done 139 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=4)]: Done 140 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=4)]: Done 141 tasks      | elapsed:   32.7s\n",
      "[Parallel(n_jobs=4)]: Done 142 tasks      | elapsed:   32.7s\n",
      "[Parallel(n_jobs=4)]: Done 143 tasks      | elapsed:   32.8s\n",
      "[Parallel(n_jobs=4)]: Done 144 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=4)]: Done 145 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=4)]: Done 146 tasks      | elapsed:   33.7s\n",
      "[Parallel(n_jobs=4)]: Done 147 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=4)]: Done 148 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=4)]: Done 149 tasks      | elapsed:   34.6s\n",
      "[Parallel(n_jobs=4)]: Done 150 tasks      | elapsed:   34.6s\n",
      "[Parallel(n_jobs=4)]: Done 151 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=4)]: Done 152 tasks      | elapsed:   35.0s\n",
      "[Parallel(n_jobs=4)]: Done 153 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=4)]: Done 155 tasks      | elapsed:   35.6s\n",
      "[Parallel(n_jobs=4)]: Done 156 tasks      | elapsed:   35.9s\n",
      "[Parallel(n_jobs=4)]: Done 157 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=4)]: Done 158 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=4)]: Done 159 tasks      | elapsed:   36.5s\n",
      "[Parallel(n_jobs=4)]: Done 160 tasks      | elapsed:   36.9s\n",
      "[Parallel(n_jobs=4)]: Done 161 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=4)]: Done 162 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=4)]: Done 163 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=4)]: Done 164 tasks      | elapsed:   37.8s\n",
      "[Parallel(n_jobs=4)]: Done 165 tasks      | elapsed:   38.2s\n",
      "[Parallel(n_jobs=4)]: Done 166 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=4)]: Done 167 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=4)]: Done 168 tasks      | elapsed:   38.7s\n",
      "[Parallel(n_jobs=4)]: Done 175 out of 175 | elapsed:   40.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Best Score: 0.6143922307873566\n",
      "Best Estimator: {'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__max_depth': 11}\n",
      "Best Model: Pipeline(steps=[('ordinalencoder',\n",
      "                 OrdinalEncoder(cols=['MPAA Rating', 'Directors', 'Country',\n",
      "                                      'Action', 'Adventure', 'Animation',\n",
      "                                      'Biography', 'Comedy', 'Crime',\n",
      "                                      'Documentary', 'Drama', 'Family',\n",
      "                                      'Fantasy', 'Film Noir', 'History',\n",
      "                                      'Horror', 'Music', 'Musical', 'Mystery',\n",
      "                                      'Romance', 'Sci-Fi', 'Short Film',\n",
      "                                      'Sport', 'Superhero', 'Thriller', 'War',\n",
      "                                      'Western'],\n",
      "                                mapping=[{'col': 'MPA...\n",
      "NaN     -2\n",
      "dtype: int64},\n",
      "                                         {'col': 'War', 'data_type': dtype('O'),\n",
      "                                          'mapping': False    1\n",
      "True     2\n",
      "NaN     -2\n",
      "dtype: int64},\n",
      "                                         {'col': 'Western',\n",
      "                                          'data_type': dtype('O'),\n",
      "                                          'mapping': False    1\n",
      "True     2\n",
      "NaN     -2\n",
      "dtype: int64}])),\n",
      "                ('simpleimputer', SimpleImputer(strategy='median')),\n",
      "                ('standardscaler', StandardScaler()),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=11, n_estimators=200,\n",
      "                                        n_jobs=1))])\n"
     ]
    }
   ],
   "source": [
    "# Model 6\n",
    "model6 = make_pipeline(\n",
    "  OrdinalEncoder(),\n",
    "  SimpleImputer(strategy='median'),\n",
    "  StandardScaler(),\n",
    "  RandomForestClassifier(\n",
    "      min_samples_split=4,\n",
    "      max_depth=15,\n",
    "      n_estimators= 200,\n",
    "      n_jobs=1)\n",
    ")\n",
    "\n",
    "param_distributions = {\n",
    "    'randomforestclassifier__max_depth' : (11, 12, 13, 14, 15),\n",
    "    'randomforestclassifier__min_samples_split': (2, 4, 6, 8, 10),\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    model6,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=40,\n",
    "    cv=7,\n",
    "    scoring='accuracy',\n",
    "    verbose = 30,\n",
    "    return_train_score=True,\n",
    "    n_jobs=4,\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print('Cross-validation Best Score:', search.best_score_)\n",
    "print('Best Estimator:', search.best_params_)\n",
    "print('Best Model:', search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 25 candidates, totalling 175 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradbrauser/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 25 is smaller than n_iter=40. Running 25 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=4)]: Done  11 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=4)]: Done  13 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=4)]: Done  15 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=4)]: Done  16 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=4)]: Done  18 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=4)]: Done  19 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=4)]: Done  20 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=4)]: Done  21 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=4)]: Done  22 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=4)]: Done  23 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=4)]: Done  25 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=4)]: Done  26 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=4)]: Done  27 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=4)]: Done  28 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=4)]: Done  29 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=4)]: Done  30 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=4)]: Done  31 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=4)]: Done  32 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=4)]: Done  34 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=4)]: Done  35 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=4)]: Done  36 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=4)]: Done  37 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=4)]: Done  38 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=4)]: Done  39 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=4)]: Done  40 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=4)]: Done  41 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=4)]: Done  43 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=4)]: Done  44 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=4)]: Done  45 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=4)]: Done  46 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=4)]: Done  47 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=4)]: Done  48 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=4)]: Done  49 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=4)]: Done  50 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=4)]: Done  51 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=4)]: Done  52 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=4)]: Done  54 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=4)]: Done  55 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=4)]: Done  56 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=4)]: Done  57 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=4)]: Done  59 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=4)]: Done  60 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=4)]: Done  61 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=4)]: Done  62 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=4)]: Done  63 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=4)]: Done  65 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=4)]: Done  66 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=4)]: Done  67 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=4)]: Done  68 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=4)]: Done  69 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=4)]: Done  70 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=4)]: Done  71 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=4)]: Done  72 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=4)]: Done  73 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=4)]: Done  74 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=4)]: Done  75 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=4)]: Done  78 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=4)]: Done  79 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=4)]: Done  80 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=4)]: Done  81 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=4)]: Done  82 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=4)]: Done  83 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=4)]: Done  84 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=4)]: Done  85 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=4)]: Done  86 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=4)]: Done  87 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=4)]: Done  88 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=4)]: Done  89 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=4)]: Done  91 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=4)]: Done  92 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=4)]: Done  93 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=4)]: Done  94 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=4)]: Done  95 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=4)]: Done  96 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=4)]: Done  97 tasks      | elapsed:   22.4s\n",
      "[Parallel(n_jobs=4)]: Done  98 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=4)]: Done  99 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=4)]: Done 100 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=4)]: Done 101 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=4)]: Done 102 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=4)]: Done 103 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=4)]: Done 104 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=4)]: Done 106 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=4)]: Done 107 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=4)]: Done 108 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=4)]: Done 109 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=4)]: Done 110 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=4)]: Done 111 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=4)]: Done 112 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=4)]: Done 113 tasks      | elapsed:   26.0s\n",
      "[Parallel(n_jobs=4)]: Done 114 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=4)]: Done 115 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=4)]: Done 116 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=4)]: Done 117 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=4)]: Done 118 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=4)]: Done 119 tasks      | elapsed:   27.2s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   27.3s\n",
      "[Parallel(n_jobs=4)]: Done 121 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=4)]: Done 122 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=4)]: Done 123 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=4)]: Done 124 tasks      | elapsed:   28.2s\n",
      "[Parallel(n_jobs=4)]: Done 125 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=4)]: Done 126 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=4)]: Done 127 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=4)]: Done 128 tasks      | elapsed:   29.1s\n",
      "[Parallel(n_jobs=4)]: Done 129 tasks      | elapsed:   29.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 130 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=4)]: Done 131 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=4)]: Done 132 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=4)]: Done 133 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=4)]: Done 134 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=4)]: Done 135 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=4)]: Done 136 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=4)]: Done 138 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=4)]: Done 139 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=4)]: Done 140 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=4)]: Done 141 tasks      | elapsed:   32.4s\n",
      "[Parallel(n_jobs=4)]: Done 142 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=4)]: Done 143 tasks      | elapsed:   32.7s\n",
      "[Parallel(n_jobs=4)]: Done 144 tasks      | elapsed:   32.8s\n",
      "[Parallel(n_jobs=4)]: Done 145 tasks      | elapsed:   33.4s\n",
      "[Parallel(n_jobs=4)]: Done 146 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=4)]: Done 147 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=4)]: Done 148 tasks      | elapsed:   33.7s\n",
      "[Parallel(n_jobs=4)]: Done 149 tasks      | elapsed:   34.3s\n",
      "[Parallel(n_jobs=4)]: Done 150 tasks      | elapsed:   34.5s\n",
      "[Parallel(n_jobs=4)]: Done 151 tasks      | elapsed:   34.5s\n",
      "[Parallel(n_jobs=4)]: Done 152 tasks      | elapsed:   34.6s\n",
      "[Parallel(n_jobs=4)]: Done 153 tasks      | elapsed:   35.2s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=4)]: Done 155 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=4)]: Done 156 tasks      | elapsed:   35.6s\n",
      "[Parallel(n_jobs=4)]: Done 157 tasks      | elapsed:   36.1s\n",
      "[Parallel(n_jobs=4)]: Done 158 tasks      | elapsed:   36.3s\n",
      "[Parallel(n_jobs=4)]: Done 159 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=4)]: Done 160 tasks      | elapsed:   36.5s\n",
      "[Parallel(n_jobs=4)]: Done 161 tasks      | elapsed:   37.1s\n",
      "[Parallel(n_jobs=4)]: Done 162 tasks      | elapsed:   37.2s\n",
      "[Parallel(n_jobs=4)]: Done 163 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=4)]: Done 164 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=4)]: Done 165 tasks      | elapsed:   38.0s\n",
      "[Parallel(n_jobs=4)]: Done 166 tasks      | elapsed:   38.2s\n",
      "[Parallel(n_jobs=4)]: Done 167 tasks      | elapsed:   38.2s\n",
      "[Parallel(n_jobs=4)]: Done 168 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=4)]: Done 175 out of 175 | elapsed:   39.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters {'randomforestclassifier__min_samples_split': 6, 'randomforestclassifier__max_depth': 13}\n",
      "Cross-validation MAE -0.6129261261174614\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "model7 = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(), \n",
    "      StandardScaler(), \n",
    "    RandomForestRegressor(random_state=42)\n",
    ")\n",
    "\n",
    "param_distributions = {\n",
    "    'targetencoder__min_samples_leaf': randint(1, 1000),     \n",
    "    'simpleimputer__strategy': ['mean', 'median'], \n",
    "    'randomforestregressor__n_estimators': 15, \n",
    "    'randomforestregressor__max_depth': 14, \n",
    "    'randomforestregressor__max_features': 0.3763983510221083, \n",
    "}\n",
    "\n",
    "search.fit(X_train, y_train);\n",
    "\n",
    "print('Best hyperparameters', search.best_params_)\n",
    "print('Cross-validation MAE', -search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ordinalencoder',\n",
       "                 OrdinalEncoder(cols=['MPAA Rating', 'Directors', 'Country',\n",
       "                                      'Action', 'Adventure', 'Animation',\n",
       "                                      'Biography', 'Comedy', 'Crime',\n",
       "                                      'Documentary', 'Drama', 'Family',\n",
       "                                      'Fantasy', 'Film Noir', 'History',\n",
       "                                      'Horror', 'Music', 'Musical', 'Mystery',\n",
       "                                      'Romance', 'Sci-Fi', 'Short Film',\n",
       "                                      'Sport', 'Superhero', 'Thriller', 'War',\n",
       "                                      'Western'],\n",
       "                                mapping=[{'col': 'MPA...\n",
       "                                         {'col': 'War', 'data_type': dtype('O'),\n",
       "                                          'mapping': False    1\n",
       "True     2\n",
       "NaN     -2\n",
       "dtype: int64},\n",
       "                                         {'col': 'Western',\n",
       "                                          'data_type': dtype('O'),\n",
       "                                          'mapping': False    1\n",
       "True     2\n",
       "NaN     -2\n",
       "dtype: int64}])),\n",
       "                ('simpleimputer', SimpleImputer(strategy='median')),\n",
       "                ('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(max_depth=13, min_samples_split=6,\n",
       "                                        n_estimators=200, n_jobs=1))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial Dependence Plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.88476\tvalidation_1-auc:0.69732\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-auc:0.91152\tvalidation_1-auc:0.66004\n",
      "[2]\tvalidation_0-auc:0.92164\tvalidation_1-auc:0.67115\n",
      "[3]\tvalidation_0-auc:0.92802\tvalidation_1-auc:0.67450\n",
      "[4]\tvalidation_0-auc:0.93146\tvalidation_1-auc:0.70562\n",
      "[5]\tvalidation_0-auc:0.93664\tvalidation_1-auc:0.69420\n",
      "[6]\tvalidation_0-auc:0.93907\tvalidation_1-auc:0.68781\n",
      "[7]\tvalidation_0-auc:0.94254\tvalidation_1-auc:0.67938\n",
      "[8]\tvalidation_0-auc:0.94817\tvalidation_1-auc:0.67603\n",
      "[9]\tvalidation_0-auc:0.94955\tvalidation_1-auc:0.66706\n",
      "[10]\tvalidation_0-auc:0.95297\tvalidation_1-auc:0.67702\n",
      "[11]\tvalidation_0-auc:0.95516\tvalidation_1-auc:0.68556\n",
      "[12]\tvalidation_0-auc:0.95737\tvalidation_1-auc:0.68393\n",
      "[13]\tvalidation_0-auc:0.96006\tvalidation_1-auc:0.68287\n",
      "[14]\tvalidation_0-auc:0.96151\tvalidation_1-auc:0.68958\n",
      "Stopping. Best iteration:\n",
      "[4]\tvalidation_0-auc:0.93146\tvalidation_1-auc:0.70562\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=1000, n_jobs=-1, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "processor = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='median')\n",
    ")\n",
    "\n",
    "X_train_processed = processor.fit_transform(X_train)\n",
    "X_val_processed = processor.transform(X_val)\n",
    "\n",
    "eval_set = [(X_train_processed, y_train), \n",
    "            (X_val_processed, y_val)]\n",
    "\n",
    "model = XGBClassifier(n_estimators=1000, n_jobs=-1)\n",
    "model.fit(X_train_processed, y_train, eval_set=eval_set, eval_metric='auc', \n",
    "          early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC for class 1:\n",
      "0.7056247580190245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "X_val_processed = processor.transform(X_val)\n",
    "class_index = 1\n",
    "y_pred_proba = model.predict_proba(X_val_processed)[:, class_index]\n",
    "print(f'Test ROC AUC for class {class_index}:')\n",
    "print(roc_auc_score(y_val, y_pred_proba)) # Ranges from 0-1, higher is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial Dependence Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting R^2 -0.17342556168343015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "gb = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    XGBRegressor(n_estimators=200, objective='reg:squarederror', n_jobs=-1)\n",
    ")\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred = gb.predict(X_val)\n",
    "print('Gradient Boosting R^2', r2_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year           0\n",
       "MPAA Rating    0\n",
       "Netflix        0\n",
       "Hulu           0\n",
       "Prime Video    0\n",
       "Disney+        0\n",
       "Directors      0\n",
       "Country        0\n",
       "Runtime        0\n",
       "Action         0\n",
       "Adventure      0\n",
       "Animation      0\n",
       "Biography      0\n",
       "Comedy         0\n",
       "Crime          0\n",
       "Documentary    0\n",
       "Drama          0\n",
       "Family         0\n",
       "Fantasy        0\n",
       "Film Noir      0\n",
       "History        0\n",
       "Horror         0\n",
       "Music          0\n",
       "Musical        0\n",
       "Mystery        0\n",
       "Romance        0\n",
       "Sci-Fi         0\n",
       "Short Film     0\n",
       "Sport          0\n",
       "Superhero      0\n",
       "Thriller       0\n",
       "War            0\n",
       "Western        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-32dfe3f45940>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m isolated = pdp_isolate(\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model3' is not defined"
     ]
    }
   ],
   "source": [
    "from pdpbox.pdp import pdp_isolate, pdp_plot\n",
    "\n",
    "feature = 'Runtime'\n",
    "\n",
    "isolated = pdp_isolate(\n",
    "    model=model3,\n",
    "    dataset=X_val,\n",
    "    model_features=X_val.columns,\n",
    "    feature=feature\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp_plot(isolated, feature_name=feature, plot_lines=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdpbox.pdp import pdp_interact, pdp_interact_plot\n",
    "\n",
    "features = ['Runtime', 'Year']\n",
    "\n",
    "interaction = pdp_interact(\n",
    "    model=model3,\n",
    "    dataset=X_val,\n",
    "    model_features=X_val.columns,\n",
    "    features=features\n",
    ")\n",
    "\n",
    "pdp_interact_plot(interaction, plot_type='grid', feature_names=features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = X_val.iloc[[0]]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.predict(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(model3)\n",
    "shap_values = explainer.shap_values(row)\n",
    "shap.initjs()\n",
    "shap.force_plot(\n",
    "    base_value=explainer.expected_value,\n",
    "    shap_values=shap_values,\n",
    "    features=row\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
