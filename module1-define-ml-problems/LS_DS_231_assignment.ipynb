{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nCc3XZEyG3XV"
   },
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 2, Sprint 3, Module 1*\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Define ML problems\n",
    "\n",
    "You will use your portfolio project dataset for all assignments this sprint.\n",
    "\n",
    "## Assignment\n",
    "\n",
    "Complete these tasks for your project, and document your decisions.\n",
    "\n",
    "- [ ] Choose your target. Which column in your tabular dataset will you predict?\n",
    "- [ ] Is your problem regression or classification?\n",
    "- [ ] How is your target distributed?\n",
    "    - Classification: How many classes? Are the classes imbalanced?\n",
    "    - Regression: Is the target right-skewed? If so, you may want to log transform the target.\n",
    "- [ ] Choose your evaluation metric(s).\n",
    "    - Classification: Is your majority class frequency >= 50% and < 70% ? If so, you can just use accuracy if you want. Outside that range, accuracy could be misleading. What evaluation metric will you choose, in addition to or instead of accuracy?\n",
    "    - Regression: Will you use mean absolute error, root mean squared error, R^2, or other regression metrics?\n",
    "- [ ] Choose which observations you will use to train, validate, and test your model.\n",
    "    - Are some observations outliers? Will you exclude them?\n",
    "    - Will you do a random split or a time-based split?\n",
    "- [ ] Begin to clean and explore your data.\n",
    "- [ ] Begin to choose which features, if any, to exclude. Would some features \"leak\" future information?\n",
    "\n",
    "If you haven't found a dataset yet, do that today. [Review requirements for your portfolio project](https://lambdaschool.github.io/ds/unit2) and choose your dataset.\n",
    "\n",
    "Some students worry, ***what if my model isn't “good”?*** Then, [produce a detailed tribute to your wrongness. That is science!](https://twitter.com/nathanwpyle/status/1176860147223867393)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle ML datasets (From 231 assignment)\n",
    "[ ] Continue to clean and explore your data.\n",
    "\n",
    "[ ] For the evaluation metric you chose, what score would you get just by guessing?\n",
    "\n",
    "[ ] Can you make a fast, first model that beats guessing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 2, Sprint 3, Module 3*\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Permutation & Boosting\n",
    "\n",
    "You will use your portfolio project dataset for all assignments this sprint.\n",
    "\n",
    "## Assignment\n",
    "\n",
    "Complete these tasks for your project, and document your work.\n",
    "\n",
    "- [ ] If you haven't completed assignment #1, please do so first.\n",
    "- [ ] Continue to clean and explore your data. Make exploratory visualizations.\n",
    "- [ ] Fit a model. Does it beat your baseline? \n",
    "- [ ] Try xgboost.\n",
    "- [ ] Get your model's permutation importances.\n",
    "\n",
    "You should try to complete an initial model today, because the rest of the week, we're making model interpretation visualizations.\n",
    "\n",
    "But, if you aren't ready to try xgboost and permutation importances with your dataset today, that's okay. You can practice with another dataset instead. You may choose any dataset you've worked with previously.\n",
    "\n",
    "The data subdirectory includes the Titanic dataset for classification and the NYC apartments dataset for regression. You may want to choose one of these datasets, because example solutions will be available for each.\n",
    "\n",
    "\n",
    "## Reading\n",
    "\n",
    "Top recommendations in _**bold italic:**_\n",
    "\n",
    "#### Permutation Importances\n",
    "- _**[Kaggle / Dan Becker: Machine Learning Explainability](https://www.kaggle.com/dansbecker/permutation-importance)**_\n",
    "- [Christoph Molnar: Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/feature-importance.html)\n",
    "\n",
    "#### (Default) Feature Importances\n",
    "  - [Ando Saabas: Selecting good features, Part 3, Random Forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
    "  - [Terence Parr, et al: Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
    "\n",
    "#### Gradient Boosting\n",
    "  - [A Gentle Introduction to the Gradient Boosting Algorithm for Machine Learning](https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/)\n",
    "  - [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf), Chapter 8\n",
    "  - _**[Gradient Boosting Explained](https://www.gormanalysis.com/blog/gradient-boosting-explained/)**_ — Ben Gorman\n",
    "  - [Gradient Boosting Explained](http://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html) — Alex Rogozhnikov\n",
    "  - [How to explain gradient boosting](https://explained.ai/gradient-boosting/) — Terence Parr & Jeremy Howard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# If you're on Colab:\n",
    "if 'google.colab' in sys.modules:\n",
    "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n",
    "\n",
    "# If you're working locally:\n",
    "else:\n",
    "    DATA_PATH = '../data/'\n",
    "    \n",
    "# Ignore this Numpy warning when using Plotly Express:\n",
    "# FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning, module='numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('/Users/bradbrauser/Desktop/Data Science/MoviesOnStreamingPlatforms_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16744, 17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which column in your tabular dataset will you predict, and how is your target distributed?\n",
    "\n",
    "The dataset has two rating features - IMDb and Rotten Tomatoes.\n",
    "\n",
    "IMDb is great for seeing what general audiences think of a movie. If you don’t care what the critics say and want to see what people like yourself think of a movie, then you should use IMDb. Just be aware that fans often skew the vote with 10-star ratings, which may inflate scores somewhat.\n",
    "\n",
    "Rotten Tomatoes offers the best overall picture of whether a movie is worth seeing at a glance. If you only trust the opinions of top critics and just want to know if a movie is at least decent, you should use Rotten Tomatoes. While the Fresh/Rotten binary can oversimplify the often complex opinions of critics, it should still help you weed out lousy films.\n",
    "\n",
    "My goal with this project is more in line with IMDb, as even though scores may be skewed a bit by fans of the movies, I still want to know what the public thinks, because it seems that more often than not critics do not always line up with the public opinion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571\n",
      "11586\n"
     ]
    }
   ],
   "source": [
    "print(df['IMDb'].isnull().sum())\n",
    "print(df['Rotten Tomatoes'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Age</th>\n",
       "      <th>IMDb</th>\n",
       "      <th>Netflix</th>\n",
       "      <th>Hulu</th>\n",
       "      <th>Prime Video</th>\n",
       "      <th>Disney+</th>\n",
       "      <th>Type</th>\n",
       "      <th>Directors</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Country</th>\n",
       "      <th>Language</th>\n",
       "      <th>Runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Inception</td>\n",
       "      <td>2010</td>\n",
       "      <td>13+</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>Action,Adventure,Sci-Fi,Thriller</td>\n",
       "      <td>United States,United Kingdom</td>\n",
       "      <td>English,Japanese,French</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>The Matrix</td>\n",
       "      <td>1999</td>\n",
       "      <td>18+</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lana Wachowski,Lilly Wachowski</td>\n",
       "      <td>Action,Sci-Fi</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Avengers: Infinity War</td>\n",
       "      <td>2018</td>\n",
       "      <td>13+</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Anthony Russo,Joe Russo</td>\n",
       "      <td>Action,Adventure,Sci-Fi</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Back to the Future</td>\n",
       "      <td>1985</td>\n",
       "      <td>7+</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Robert Zemeckis</td>\n",
       "      <td>Adventure,Comedy,Sci-Fi</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>The Good, the Bad and the Ugly</td>\n",
       "      <td>1966</td>\n",
       "      <td>18+</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sergio Leone</td>\n",
       "      <td>Western</td>\n",
       "      <td>Italy,Spain,West Germany</td>\n",
       "      <td>Italian</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ID                           Title  Year  Age  IMDb  Netflix  \\\n",
       "0           0   1                       Inception  2010  13+   8.8        1   \n",
       "1           1   2                      The Matrix  1999  18+   8.7        1   \n",
       "2           2   3          Avengers: Infinity War  2018  13+   8.5        1   \n",
       "3           3   4              Back to the Future  1985   7+   8.5        1   \n",
       "4           4   5  The Good, the Bad and the Ugly  1966  18+   8.8        1   \n",
       "\n",
       "   Hulu  Prime Video  Disney+  Type                       Directors  \\\n",
       "0     0            0        0     0               Christopher Nolan   \n",
       "1     0            0        0     0  Lana Wachowski,Lilly Wachowski   \n",
       "2     0            0        0     0         Anthony Russo,Joe Russo   \n",
       "3     0            0        0     0                 Robert Zemeckis   \n",
       "4     0            1        0     0                    Sergio Leone   \n",
       "\n",
       "                             Genres                       Country  \\\n",
       "0  Action,Adventure,Sci-Fi,Thriller  United States,United Kingdom   \n",
       "1                     Action,Sci-Fi                 United States   \n",
       "2           Action,Adventure,Sci-Fi                 United States   \n",
       "3           Adventure,Comedy,Sci-Fi                 United States   \n",
       "4                           Western      Italy,Spain,West Germany   \n",
       "\n",
       "                  Language  Runtime  \n",
       "0  English,Japanese,French    148.0  \n",
       "1                  English    136.0  \n",
       "2                  English    149.0  \n",
       "3                  English    116.0  \n",
       "4                  Italian    161.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the Rotten Tomatoes features has over 11,000 missing ratings, \n",
    "# I'm going to just drop the Rotten Tomatoes column\n",
    "\n",
    "df = df.drop(['Rotten Tomatoes'], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16173, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=['IMDb'], how='all')\n",
    "df['IMDb'].isnull().sum()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(df, thresh=500):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Setting Title as index\n",
    "    df.set_index(df['Year'], inplace = True)    \n",
    "    \n",
    "    # Dropping rows if nulls exist\n",
    "    df.dropna(subset=['IMDb'], how='all')\n",
    "    \n",
    "    # Creating new Rating colums\n",
    "    df['Good?'] = df['IMDb'] >= 7.0\n",
    "        \n",
    "    # Dropping unnecessary values\n",
    "    df.drop(['Unnamed: 0', 'ID', 'Title', 'Type', 'ID', 'Year', \n",
    "             'Directors', 'Genres', 'Country', 'Language', 'IMDb'], \n",
    "            axis=1, inplace=True)\n",
    "    \n",
    "    # Split label and feature matrix\n",
    "    y = df['Good?']\n",
    "    df.drop(['Good?'], axis=1, inplace=True)\n",
    "    \n",
    "    return df, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16173, 6)\n",
      "(16173,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    0.77432\n",
       "True     0.22568\n",
       "Name: Good?, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Wrangling\n",
    "X, y = wrangle(df)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Train test split on years movies were released\n",
    "cutoff = 2010\n",
    "X_train, y_train = X[X.index < cutoff], y[y.index < cutoff]\n",
    "X_val, y_val = X[X.index >= cutoff], y[y.index >= cutoff]\n",
    "\n",
    "# Baseline\n",
    "y_train.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import category_encoders as ce\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8352479278755272\n",
      "Validation Accuracy: 0.6934165232358004\n"
     ]
    }
   ],
   "source": [
    "# Building model 1\n",
    "model1 = Pipeline([\n",
    "    ('oe', OrdinalEncoder()),\n",
    "    ('impute', SimpleImputer()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(criterion='entropy', \n",
    "                                          max_depth=50, n_estimators=200, \n",
    "                                          min_samples_leaf=1, \n",
    "                                          random_state=42))\n",
    "])\n",
    "\n",
    "# Fitting the model\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "print('Training Accuracy:', model1.score(X_train, y_train))\n",
    "print('Validation Accuracy:', model1.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8352479278755272\n",
      "Validation Accuracy: 0.6970740103270223\n"
     ]
    }
   ],
   "source": [
    "# Building model 2\n",
    "model2 = Pipeline([\n",
    "                  ('ohe', OneHotEncoder()),\n",
    "                  ('impute', SimpleImputer()),\n",
    "                  ('scaler', StandardScaler()),\n",
    "                  ('classifier', RandomForestClassifier(criterion='entropy', \n",
    "                                                        max_depth=50, n_estimators=200, \n",
    "                                                        min_samples_leaf=1, random_state=42))\n",
    "])\n",
    "\n",
    "# Fitting the model\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "print('Training Accuracy:', model2.score(X_train, y_train))\n",
    "print('Validation Accuracy:', model2.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7948233241238912\n",
      "Validation Accuracy: 0.7389199655765921\n"
     ]
    }
   ],
   "source": [
    "# Model 3\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "model3 = make_pipeline(\n",
    "    ce.OneHotEncoder(use_cat_names=True), \n",
    "    SimpleImputer(), \n",
    "    StandardScaler(), \n",
    "    RandomForestClassifier(n_estimators = 10, min_samples_split = 40))\n",
    "\n",
    "# Fitting the model\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "print('Training Accuracy:', model3.score(X_train, y_train))\n",
    "print('Validation Accuracy:', model3.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradbrauser/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 7 is smaller than n_iter=40. Running 7 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.1071s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 7 candidates, totalling 49 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done  16 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done  18 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done  20 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done  22 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done  26 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done  28 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done  30 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done  32 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done  34 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=4)]: Done  36 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=4)]: Done  38 out of  49 | elapsed:    1.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  40 out of  49 | elapsed:    1.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  42 out of  49 | elapsed:    1.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  44 out of  49 | elapsed:    1.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  46 out of  49 | elapsed:    1.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  49 out of  49 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'e'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-907c7b042d27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cross-validation Best Score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    390\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 392\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                                         indices=indices)\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    895\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_classification\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m                 criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n\u001b[0m\u001b[1;32m    334\u001b[0m                                                          self.n_classes_)\n\u001b[1;32m    335\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'e'"
     ]
    }
   ],
   "source": [
    "# Model 5\n",
    "model5 = make_pipeline(\n",
    "  OrdinalEncoder(),\n",
    "  SimpleImputer(strategy='median'),\n",
    "  StandardScaler(),\n",
    "  RandomForestClassifier(\n",
    "      min_samples_split=3,\n",
    "      max_depth=15,\n",
    "      n_estimators= 200,\n",
    "      n_jobs=1)\n",
    ")\n",
    "\n",
    "param_distributions = {\n",
    "    'randomforestclassifier__criterion': ('entropy'),\n",
    "#     'randomforestclassifier__max_depth' : (11, 12, 13, 14, 15),\n",
    "#     'randomforestclassifier__min_samples_split': (2),\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    model5,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=40,\n",
    "    cv=7,\n",
    "    scoring='accuracy',\n",
    "    verbose = 30,\n",
    "    return_train_score=True,\n",
    "    n_jobs=4,\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print('Cross-validation Best Score:', search.best_score_)\n",
    "print('Best Estimator:', search.best_params_)\n",
    "print('Best Model:', search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8098007852261161\n",
      "Validation Accuracy: 0.732250430292599\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model6 = make_pipeline(ce.OrdinalEncoder(),\n",
    "                         XGBClassifier(n_estimators=100,\n",
    "                                       random_state=42,\n",
    "                                       n_jobs=-1)\n",
    ")\n",
    "\n",
    "model6.fit(X_train, y_train)\n",
    "\n",
    "print('Training Accuracy:', model6.score(X_train, y_train))\n",
    "print('Validation Accuracy:', model6.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fe5bf744d50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plot_confusion_matrix(model6, X_val, y_val, values_format='.0f', xticks_rotation='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.92      0.84      7053\n",
      "        True       0.36      0.14      0.20      2243\n",
      "\n",
      "    accuracy                           0.73      9296\n",
      "   macro avg       0.57      0.53      0.52      9296\n",
      "weighted avg       0.67      0.73      0.69      9296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model6.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year\n",
      "2010    148.0\n",
      "2018    149.0\n",
      "2018    117.0\n",
      "2012    165.0\n",
      "2015    118.0\n",
      "Name: Runtime, dtype: float64\n",
      "\n",
      "90.0     560\n",
      "95.0     272\n",
      "92.0     247\n",
      "85.0     245\n",
      "89.0     235\n",
      "        ... \n",
      "197.0      1\n",
      "16.0       1\n",
      "256.0      1\n",
      "3.0        1\n",
      "167.0      1\n",
      "Name: Runtime, Length: 199, dtype: int64\n",
      "Validation accuracy with Runtime: 0.732250430292599\n",
      "Validation accuracy with Runtime permuted: 0.7030981067125646\n",
      "Permutation importance: 0.02915232358003439\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "feature = 'Runtime'\n",
    "print(X_val[feature].head())\n",
    "print()\n",
    "print(X_val[feature].value_counts())\n",
    "\n",
    "X_val_permuted = X_val.copy()\n",
    "X_val_permuted[feature] = np.random.permutation(X_val_permuted[feature])\n",
    "\n",
    "acc = model6.score(X_val, y_val)\n",
    "acc_permuted = model6.score(X_val_permuted, y_val)\n",
    "\n",
    "print(f'Validation accuracy with {feature}:', acc)\n",
    "print(f'Validation accuracy with {feature} permuted:', acc_permuted)\n",
    "print(f'Permutation importance:', acc - acc_permuted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradbrauser/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/bradbrauser/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0311\n",
       "                \n",
       "                    &plusmn; 0.0047\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Runtime\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0067\n",
       "                \n",
       "                    &plusmn; 0.0024\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Prime Video\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.51%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0049\n",
       "                \n",
       "                    &plusmn; 0.0024\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Age\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.51%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0037\n",
       "                \n",
       "                    &plusmn; 0.0009\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Disney+\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 96.26%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0028\n",
       "                \n",
       "                    &plusmn; 0.0033\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Netflix\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 93.71%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0060\n",
       "                \n",
       "                    &plusmn; 0.0019\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Hulu\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "# Ignore warnings\n",
    "\n",
    "transformers = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='median')\n",
    ")\n",
    "\n",
    "X_train_transformed = transformers.fit_transform(X_train)\n",
    "X_val_transformed = transformers.transform(X_val)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=20, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train_transformed, y_train)\n",
    "\n",
    "\n",
    "\n",
    "feature_names = X_val.columns.tolist()\n",
    "\n",
    "permuter = PermutationImportance(\n",
    "    model,\n",
    "    scoring='accuracy',\n",
    "    n_iter=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "permuter.fit(X_val_transformed, y_val)\n",
    "\n",
    "eli5.show_weights(\n",
    "    permuter,\n",
    "    top=None,\n",
    "    feature_names=feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
